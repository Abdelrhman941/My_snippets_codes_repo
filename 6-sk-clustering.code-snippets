{
"K-Means Clustering": {
    "prefix": "sk: (cluster) kmeans",
    "description": "Create and fit K-Means clustering model",
    "body": [
        "from sklearn.cluster import KMeans",
        "",
        "${1:kmeans} = KMeans(",
        "    n_clusters=${2:3},",
        "    random_state=${3:42}",
        ")",
        "cluster_labels = $1.fit_predict(${4:X})",
        "",
        "# Get cluster centers",
        "cluster_centers = $1.cluster_centers_",
        "print(f'Number of clusters: {$1.n_clusters}')",
        "print(f'Inertia: {$1.inertia_:.4f}')",
    ]
},
// ---------------------------------
"DBSCAN Clustering": {
    "prefix": "sk: (cluster) dbscan",
    "description": "Create and fit DBSCAN clustering model",
    "body": [
        "from sklearn.cluster import DBSCAN",
        "",
        "${1:dbscan} = DBSCAN(",
        "    eps=${2:0.5},",
        "    min_samples=${3:5}",
        ")",
        "cluster_labels = $1.fit_predict(${4:X})",
        "",
        "# Number of clusters (excluding noise)",
        "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)",
        "n_noise    = list(cluster_labels).count(-1)",
        "print(f'Number of clusters     : {n_clusters}')",
        "print(f'Number of noise points : {n_noise}')",
    ]
},
// ---------------------------------
"Hierarchical Clustering": {
    "prefix": "sk: (cluster) hierarchical",
    "description": "Create and fit Agglomerative (Hierarchical) clustering model",
    "body": [
        "from sklearn.cluster import AgglomerativeClustering",
        "",
        "${1:hierarchical} = AgglomerativeClustering(",
        "    n_clusters=${2:3},",
        "    linkage='${3|ward,complete,average,single|}'",
        ")",
        "cluster_labels = $1.fit_predict(${4:X})",
        "",
        "print(f'Number of clusters: {$1.n_clusters}')",
    ]
},
// ---------------------------------
"Gaussian Mixture Model": {
    "prefix": "sk: (cluster) GMM",
    "description": "Create and fit Gaussian Mixture Model for clustering",
    "body": [
        "from sklearn.mixture import GaussianMixture",
        "",
        "${1:gmm} = GaussianMixture(",
        "    n_components=${2:3},",
        "    random_state=${3:42}",
        ")",
        "$1.fit(${4:X})",
        "cluster_labels = $1.predict($4)",
        "",
        "print(f'Number of components: {$1.n_components}')",
        "print(f'AIC: {$1.aic($4):.4f}')",
        "print(f'BIC: {$1.bic($4):.4f}')",
    ]
},
// ---------------------------------
"Clustering Evaluation": {
    "prefix": "sk: (cluster) evaluation",
    "description": "Evaluate clustering performance with multiple metrics",
    "body": [
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score",
        "",
        "# Silhouette score (higher is better, range: -1 to 1)",
        "silhouette = silhouette_score(${1:X}, ${2:cluster_labels})",
        "print(f'Silhouette Score: {silhouette:.4f}')",
        "",
        "# If true labels are available",
        "# ari = adjusted_rand_score(${3:y_true}, $2)",
        "# nmi = normalized_mutual_info_score($3, $2)",
        "# print(f'Adjusted Rand Index: {ari:.4f}')",
        "# print(f'Normalized Mutual Information: {nmi:.4f}')",
    ]
},
// ---------------------------------
"Elbow Method": {
    "prefix": "sk: (cluster) elbow",
    "description": "Find optimal number of clusters using elbow method",
    "body": [
        "from sklearn.cluster import KMeans",
        "import matplotlib.pyplot as plt",
        "",
        "# Range of cluster numbers to try",
        "k_range = range(1, ${1:11})",
        "inertias = []",
        "",
        "for k in k_range:",
        "    kmeans = KMeans(n_clusters=k, random_state=${2:42})",
        "    kmeans.fit(${3:X})",
        "    inertias.append(kmeans.inertia_)",
        "",
        "# Plot elbow curve",
        "plt.figure(figsize=(10, 6))",
        "plt.plot(k_range, inertias, 'bo-')",
        "plt.xlabel('Number of Clusters (k)')",
        "plt.ylabel('Inertia')",
        "plt.title('Elbow Method for Optimal k')",
        "plt.grid(True)",
        "plt.show()",
    ]
}
}
